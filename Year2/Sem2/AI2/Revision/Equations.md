# Equations

### Odds and logit
![[Pasted image 20240506154251.png]]
![[Pasted image 20240506154306.png]]
### Entropy
$$H(X)=-\sum^n_i P(X=x_i) log_b P(X=x_i)$$

### Joint Entropy
$$H(X,Y)=-\sum_{x_i \in R_X} \sum_{y_i \in R_Y} P(x_i, y_i)\space log(x_i, y_i)$$

### Conditional Entropy
![[Pasted image 20240502161131.png]]

### Mutual Information
![[Pasted image 20240502161604.png]]

### Bayesian Networks
![[Pasted image 20240506154652.png]]
``